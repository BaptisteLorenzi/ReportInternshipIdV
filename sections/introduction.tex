\section{Introduction}\label{sec:introduction}

\textit{During my internship in Olivier Marre's team at l'Institut de la
    Vision, I am
    focusing on computational modeling of the retina. Olivier Marre's team is an
    interdisciplinary laboratory, hosting four professors and a dozen of interns,
    Ph.D. students and post-docs, working hand in hand to advance research
    on the retina. They all have various backgrounds mainly from biology,
    theoretical physics and engineering. In the context of this project, I've been
    working
    closely with Samuele Virgili, a third-year Ph.D. student, whose previous and
    current projects all focus on the modeling of retinal ganglion cells.}

% Context
The ability of the visual system to process complex stimuli on different
temporal and spatial scales is remarkable.
Natural environments are such complex stimuli, and extracting the relevant
features at all times is crucial for many species.
% Here I already insist on two notions: natural stim and temporal complexity

Both the accessibility and apparent complexity	of the retina make it a
perfect candidate for the study of the front-end of visual processing
\citep{gollisch_eye_2010}. In the mouse, the retina is composed of more
than 30 parallel feature channels, embodied by ganglion cell types. Through
their axons, the optic nerve, they provide information to numerous visual areas
in the brain. % Introducing the animal model
A few channels are active in the encoding of basic features including luminance
changes and motion, that are only combined in more downstream areas. Other
channels however are known to play a role in the extraction of specific
features of natural scenes.

% Introducing adaptation, with examples
An important feature of natural scenes is the diversity of contrast levels in
one scene. This diversity can be both spatial (plain and detailed object side
to side) and temporal (sudden apparition of an object). It is known that the
visual system adapts to the diversity of fluctuations in the scene. This
adaptation begins in the retina. By probing the retina with flickers of
different intensities, Baccus and colleagues revealed two distinct phases of
sensitivity change in the retina: one fast (<0.1s) and one slow (over ~10s)
\citep{baccus_fast_2002}.
In another study, Garvert et al. revealed that contrast adaptation also
happens at different scales, either at the whole scene scale (global contrast
adaptation) or within one ganglion cell receptive field, the part of the visual
field that the cell receives inputs from (local contrast adaptation)
\citep{garvert_local_2013}.

% Intoducing  natural scenes
Still, we currently lack an explanation of the features extracted by many
channels and how they adapt to diverse scenes. One of the historical
reasons for this is that synthetic stimuli used
to study retinal responses are not complex enough to activate these channels.
Hence, they cannot uncover critical response properties encountered in natural
environments. % Please rewrite this sentence

In practice, Karamanlis and colleagues \citep{kim_nonlinear_2020} have
probed a larger complexity in retinal spatial non-linearities thanks to stimuli
capturing the statistics of natural environments.
As those non-linearities cannot be captured by Linear-Nonlinear (LN) models,
convolutional neural networks (CNNs) have become the state-of-the-art approach
for predictive modeling of visual processing, not only in the retina but also
in higher visual areas \citep{mcintosh_deep_2017}.
% Add an example with the citation ?

% \textbf{Insight on methods}
Here, we combined the power of CNN-based modeling with large-scale
mutli-electrode array (MEA) recordings from RGCs to investigate the mechanisms
of fast
adaptation in the retina under natural stimulus conditions. To this end, we
recorded RGC responses to flashed images paired together. Each pair is composed
of a synthetic adaptation image followed by a natural image. We were able to
identify different trends in the responses of RGCs to natural images, depending
on the adaptation image. % Should I introduce LSTA here ?

To investigate the diversity of this adaptation process and its implementation,
we paired deep convolutional models with more traditional modeling. We trained
a CNN model on RGC responses to a movie of flashed images. After training, we
study how this model generalized to images after being adapted with
patterns it wasn't trained to. By tweaking part of the model at the inference
level, We hope to show that temporal mechanisms such as gain-control play a
major role in the fast adaptation of RGCs in a natural context.
